{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas\n",
    "import kfold_learning as kfl\n",
    "from sklearn import datasets\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's load some data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data = datasets.california_housing.fetch_california_housing()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "features = pandas.DataFrame(data.data, columns=data.feature_names)\n",
    "features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data.feature_names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "split the data into training (2/3) and testing (1/3) sets, then, set our X and y variables for train and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tr_X, te_X = train_test_split(features, train_size = 0.67)\n",
    "target = pandas.Series(data.target)\n",
    "tr_y = target[tr_X.index]\n",
    "te_y = target[te_X.index]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we'll run the model. Using default settings, kfold_feature_learning expects a regression problem and will run nested 10-fold cross-validation of LassoCV. Let's run it with the defaults, however, we will not apply the model to our test data just yet..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "output = kfl.kfold_feature_learning(tr_X, te_X, tr_y, te_y, \n",
    "                                    hide_test=True) # don't apply to test data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "because we didn't burn the test data, we can tweak some of the parameters to see if we can improve the validation accuracy (though it is not a guarantee that this will improve the model generalizibility"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's start by changing the number folds in the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "output = kfl.kfold_feature_learning(tr_X, te_X, tr_y, te_y,\n",
    "                                    folds = 20,\n",
    "                                    hide_test=True) # don't apply to test data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also set the model to only include features that are significantly associated with the target at a specified p-value threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "output = kfl.kfold_feature_learning(tr_X, te_X, tr_y, te_y,\n",
    "                                    folds = 3, p_cutoff = 0.001,\n",
    "                                    hide_test=True) # don't apply to test data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Perhaps you would rather run a different type of model? Just pass it as the clf argument"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn import linear_model\n",
    "output = kfl.kfold_feature_learning(tr_X, te_X, tr_y, te_y,\n",
    "                                    folds = 3, \n",
    "                                    clf = linear_model.RidgeCV(),\n",
    "                                    hide_test=True) # don't apply to test data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The kfold_feature_learning function will also accept grid_search type models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "params = {'loss': ['squared_loss','huber','epsilon_insensitive',\n",
    "                   'squared_epsilon_insensitive'],\n",
    "          'penalty': ['none', 'l2', 'l1'],\n",
    "          'alpha': [0.000001, 0.00001, 0.0001, 0.001, 0.01, 0.1]} \n",
    "selector = GridSearchCV(linear_model.SGDRegressor(random_state=123),\n",
    "                        [params],cv=10, scoring = 'r2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "output = kfl.kfold_feature_learning(tr_X, te_X, tr_y, te_y,\n",
    "                                    folds = 3, \n",
    "                                    clf = selector,\n",
    "                                    search = True, # req. if using grid search\n",
    "                                    hide_test=True) # don't apply to test data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are other parameters to explore as well. You can learn more by viewing the docstring: kfl.kfold_feature_learning? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "but let's go ahead and apply a model to our test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "output = kfl.kfold_feature_learning(tr_X, te_X, tr_y, te_y,\n",
    "                                    folds = 20,\n",
    "                                    hide_test=False) # apply to test data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Many relevant aspects of the model can be found in the output. We can use these to explore our model further"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "output.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, let's visualize feature importances, which can also be used to generalize the model to another dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "list(zip(data.feature_names,\n",
    "         output['final_model_weights']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the output, we can visualize the predicted vs. observed target values for the test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.scatter(output['test_predicted'], te_y)\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Observed')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I started integrating support for classifiers, but I ran out of time. Right now, the classification aspect of the code *does not work* so don't bother with it."
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:py3]",
   "language": "python",
   "name": "conda-env-py3-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
